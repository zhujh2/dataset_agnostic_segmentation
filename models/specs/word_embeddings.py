from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from abc import ABCMeta, abstractmethod

import tensorflow as tf
from tensorflow.contrib import slim
from tensorflow.contrib.keras.api.keras import backend as Kb

from models.specs import TFNetwork
from models.specs.roi_pooling_features import iou_prediction


def phoc_prediction(features, phoc_dim, scope, reuse=None, L2_reg=0.0, act_func=tf.nn.relu, large_topology=False, dropout=0.0):

    with slim.arg_scope(_args_scope(act_func, L2_reg)):
        with tf.variable_scope(scope, scope, [features], reuse=reuse) as sc:
            end_points_collection = sc.name + '_end_points'
            # Collect outputs for conv2d, fully_connected and max_pool2d.
            with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], outputs_collections=end_points_collection):
                if large_topology:
                    phoc = slim.conv2d(features, 1024, [1, 1], stride=1, activation_fn=act_func, padding='VALID', scope='fc4_phoc')
                    phoc = slim.conv2d(phoc, 1024, [1, 1], stride=1, activation_fn=act_func, padding='VALID', scope='fc5_phoc')
                    phoc = slim.conv2d(phoc, 1024, [1, 1], stride=1, activation_fn=act_func, padding='VALID', scope='fc6_phoc')
                    phoc = slim.conv2d(phoc, phoc_dim, [1, 1], stride=1, activation_fn=None, padding='VALID', scope='fc7_phoc')
                else:
                    phoc = slim.conv2d(features, 1024, [1, 1], stride=1, activation_fn=act_func, padding='VALID', scope='fc1')
                    phoc = slim.dropout(phoc, keep_prob=1 - dropout, is_training=Kb.learning_phase(), scope='dropout_phoc1')
                    phoc = slim.conv2d(phoc, 1024, [1, 1], stride=1, activation_fn=act_func, padding='VALID', scope='fc2')
                    phoc = slim.dropout(phoc, keep_prob=1 - dropout, is_training=Kb.learning_phase(), scope='dropout_phoc2')
                    phoc = slim.conv2d(phoc, phoc_dim, [1, 1], stride=1, activation_fn=None, padding='VALID', scope='linear')
                phoc = tf.squeeze(phoc, name='phoc_embd')

    return phoc


def phoc_loss_func(y, y_hat, scope, reduction=tf.reduce_mean):
    """
    Take phoc assignments to box proposals (y) and calculate loss relative to predicted
    PHOCs (y_hat)
    :param y: (tf.Tensor) assigned PHOCs e.g. by random_rois op
    :param y_hat: predicted PHOCs
    :param y_assigned_labels: proposal box labels also generated by random_rois op (self.random_boxes_labels)
    :param iou_lables_thresh: (int) what IoU coverage classes should we take for PHOC training.
    :return: (scalar)
    """
    with tf.variable_scope('%s/loss' % scope, values=[y, y_hat]):
        xent_vec = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_hat, name='phoc_sigmoid_xent_vec')
        loss = reduction(xent_vec, name='phoc_loss')
    return loss


def _args_scope(act_func, L2_reg):
    with slim.arg_scope([slim.conv2d],
                        activation_fn=act_func,
                        weights_regularizer=slim.l2_regularizer(L2_reg)
                        ):
        with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:
            return arg_sc


class StdPHOC(object):
    """ Make Sure all PHOC nets define base_pooling and phocs"""
    __metaclass__ = ABCMeta

    @abstractmethod
    def base_pooling(self, x, b):
        pass

    @abstractmethod
    def phocs(self, v_phoc):
        pass


class PhocEmbedding(TFNetwork, StdPHOC):

    def __init__(self, output_shape, act_func=tf.nn.relu, **kwargs):
        super(PhocEmbedding, self).__init__(**kwargs)
        act_funcs = {'relu': tf.nn.relu, 'tanh': tf.nn.tanh}
        self.act_func = act_funcs.get(self.args.phoc_act, tf.nn.relu)
        self.output_shape = output_shape
        self._roi_pool_call = 0
        self._phoc_calls = 0

    def base_pooling(self, x, b):
        reuse = self.get_reuse(self._roi_pool_call)
        self._roi_pool_call += 1
        scope = self.scope
        L2_reg = self.args.box_filter_L2_reg
        dropout = self.args.dropout

        def _args_scope():
            with slim.arg_scope([slim.conv2d, slim.fully_connected], activation_fn=self.act_func,
                                weights_regularizer=slim.l2_regularizer(L2_reg)
                                ):
                with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:
                    return arg_sc

        with slim.arg_scope(_args_scope()):
            with tf.variable_scope(scope, scope, [x, b], reuse=reuse) as sc:
                end_points_collection = sc.name + '_end_points'
                # Collect outputs for conv2d, fully_connected and max_pool2d.
                with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],
                                    outputs_collections=end_points_collection):
                    boxes_input = tf.identity(b[:, 1:], name='boxes')
                    batch_idx = tf.cast(b[:, 0], dtype=tf.int32, name='batch_idx')

                    pooled_features = tf.image.crop_and_resize(x, boxes_input, batch_idx, crop_size=self.output_shape)
                    phoc_w = slim.conv2d(pooled_features, 1024, [1, 9], stride=[1, 1], padding='VALID', scope='conv1_phoc')
                    phoc_w = slim.conv2d(phoc_w, 1024, [2, 1], stride=[1, 1], padding='VALID', scope='conv2_phoc')
                    phoc_w = slim.dropout(phoc_w, keep_prob=dropout, is_training=Kb.learning_phase(), scope='dropout_phoc1')

                    phoc_w = slim.conv2d(phoc_w, 1024, [2, 1], stride=[1, 1], padding='VALID', scope='conv3_phoc')
                    phoc_w = slim.dropout(phoc_w, keep_prob=dropout, is_training=Kb.learning_phase(), scope='dropout_phoc2')

                    phoc_h = slim.conv2d(pooled_features, 1024, [3, 3], stride=[1, 1], padding='VALID', scope='conv4_phoc')
                    phoc_h = slim.conv2d(phoc_h, 1024, [1, 3], stride=[1, 1], padding='VALID', scope='conv5_phoc')
                    phoc_h = slim.dropout(phoc_h, keep_prob=dropout, is_training=Kb.learning_phase(), scope='dropout_phoc3')

                    phoc_h = slim.conv2d(phoc_h, 1024, [1, 3], stride=[1, 1], padding='VALID', scope='conv6_phoc')
                    phoc_h = slim.dropout(phoc_h, keep_prob=dropout, is_training=Kb.learning_phase(), scope='dropout_phoc4')

                    phoc_h = slim.conv2d(phoc_h, 1024, [1, 3], stride=[1, 1], padding='VALID', scope='conv6a_phoc')

                    net = tf.concat([phoc_w, phoc_h], axis=-1)
                    net = slim.conv2d(net, 1024, [1, 1], stride=1, scope='fc7')
        return net

    def phocs(self, v_phoc):
        reuse = self.get_reuse(self._phoc_calls)
        self._phoc_calls += 1
        return phoc_prediction(v_phoc, phoc_dim=self.args.phoc_dim, L2_reg=self.args.box_filter_L2_reg, scope=self.scope,
                               dropout=self.args.dropout, reuse=reuse)


class MyOldPHOC(PhocEmbedding):

    def __init__(self, **kwargs):
        super(MyOldPHOC, self).__init__(**kwargs)
        self._iou_calls = 0

    def base_pooling(self, x, b):
        reuse = self.get_reuse(self._roi_pool_call)
        self._roi_pool_call += 1
        scope = self.scope
        L2_reg = self.args.box_filter_L2_reg
        dropout = self.args.dropout

        def _args_scope():
            with slim.arg_scope([slim.conv2d, slim.fully_connected], activation_fn=self.act_func,
                                weights_regularizer=slim.l2_regularizer(L2_reg)
                                ):
                with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:
                    return arg_sc

        with slim.arg_scope(_args_scope()):
            with tf.variable_scope(scope, scope, [x, b], reuse=reuse) as sc:
                end_points_collection = sc.name + '_end_points'
                # Collect outputs for conv2d, fully_connected and max_pool2d.
                with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],
                                    outputs_collections=end_points_collection):
                    boxes_input = tf.identity(b[:, 1:], name='boxes')
                    batch_idx = tf.cast(b[:, 0], dtype=tf.int32, name='batch_idx')
                    pooled_features = tf.image.crop_and_resize(x, boxes_input, batch_idx, crop_size=self.output_shape)
                    net = slim.conv2d(pooled_features, 1024, self.output_shape, stride=[1, 1], padding='VALID', scope='conv1_phoc')
                    net = slim.conv2d(net, 1024, [1, 1], stride=[1, 1], padding='VALID', scope='conv2_phoc')
                    # TODO: remove the flags
                    if not self.args.tiny_phoc:
                        net = slim.dropout(net, keep_prob=1 - dropout, is_training=Kb.learning_phase(), scope='dropout_phoc1')
                        net = slim.conv2d(net, 1024, [1, 1], stride=[1, 1], padding='VALID', scope='conv3_phoc')
                    if not self.args.tiny_phoc and not self.args.bigger_phoc:
                        net = slim.dropout(net, keep_prob=1 - dropout, is_training=Kb.learning_phase(), scope='dropout_phoc2')
                        net = slim.conv2d(net, 1024, [1, 1], stride=[1, 1], padding='VALID', scope='conv4_phoc')
                    net = slim.dropout(net, keep_prob=1 - dropout, is_training=Kb.learning_phase(), scope='dropout_phoc3')
                    net = slim.conv2d(net, 1024, [1, 1], stride=1, scope='phoc_feature')
        return net

    def phocs(self, v_phoc, act_func=tf.nn.relu, ):
        reuse = self.get_reuse(self._phoc_calls)
        self._phoc_calls += 1
        phoc_dim = self.args.phoc_dim

        with slim.arg_scope(_args_scope(act_func, self.args.box_filter_L2_reg)):
            with tf.variable_scope(self.scope, self.scope, [v_phoc], reuse=reuse) as sc:
                end_points_collection = sc.name + '_end_points'
                # Collect outputs for conv2d, fully_connected and max_pool2d.
                with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],
                                    outputs_collections=end_points_collection):
                    phoc = slim.conv2d(v_phoc, phoc_dim, [1, 1], stride=1, activation_fn=None, padding='VALID', scope='linear')
                    phoc = tf.squeeze(phoc, name='phoc_embd')
        return phoc

    def aux_iou(self, features):
        reuse = self.get_reuse(self._iou_calls)
        self._iou_calls += 1
        iou_pred = iou_prediction(features, num_classes=self.args.box_filter_num_clsses, scope=self.scope,
                                  L2_reg=self.args.box_filter_L2_reg, reuse=reuse)
        return iou_pred
